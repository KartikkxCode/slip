Slip 13


Q.1. Create RNN model and analyze the Google stock price dataset. Find out increasing or     
decreasing trends of stock price for the next day.

# ========================================
# RNN (LSTM) for Next-Day Stock Trend: GOOGL
# Using Local CSV instead of yfinance
# ========================================

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import tensorflow as tf
from tensorflow.keras import layers, models

# ---------------------------
# 1. Load Local CSV
# ---------------------------
df = pd.read_csv("GOOGL_sample.csv")   # <- put file in same folder
df = df[['Date','Open','High','Low','Close','Volume']]
df['Date'] = pd.to_datetime(df['Date'])
df = df.sort_values('Date').reset_index(drop=True)

print("Data loaded:", df.shape)
print(df.head())

# ---------------------------
# 2. Feature Engineering
# ---------------------------
df['Return'] = df['Close'].pct_change()
df['SMA_5'] = df['Close'].rolling(5).mean()
df['SMA_10'] = df['Close'].rolling(10).mean()
df['Vol_SMA_5'] = df['Volume'].rolling(5).mean()

df.dropna(inplace=True)

# Label: 1 if next day's Close > today's Close, else 0
df['Close_next'] = df['Close'].shift(-1)
df.dropna(inplace=True)
df['Label'] = (df['Close_next'] > df['Close']).astype(int)

# Features for training
features = ['Close','Return','SMA_5','SMA_10','Vol_SMA_5']
scaler = MinMaxScaler()
X_scaled = scaler.fit_transform(df[features])

# ---------------------------
# 3. Build Sequences (Sliding Window)
# ---------------------------
WINDOW = 30
X, y = [], []
for i in range(WINDOW, len(X_scaled)):
    X.append(X_scaled[i-WINDOW:i])
    y.append(df['Label'].iloc[i])
X, y = np.array(X), np.array(y)

print("X shape:", X.shape, "y shape:", y.shape)

# ---------------------------
# 4. Train/Test Split (chronological)
# ---------------------------
split = int(0.8*len(X))
X_train, X_test = X[:split], X[split:]
y_train, y_test = y[:split], y[split:]

# ---------------------------
# 5. LSTM Model
# ---------------------------
model = models.Sequential([
    layers.Input(shape=(WINDOW, X.shape[2])),
    layers.LSTM(64, return_sequences=True),
    layers.Dropout(0.2),
    layers.LSTM(32),
    layers.Dropout(0.2),
    layers.Dense(16, activation='relu'),
    layers.Dense(1, activation='sigmoid')
])
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
model.summary()

# ---------------------------
# 6. Train
# ---------------------------
history = model.fit(X_train, y_train, epochs=20, batch_size=16,
                    validation_split=0.1, verbose=1)

# Plot training history
plt.plot(history.history['accuracy'], label='train acc')
plt.plot(history.history['val_accuracy'], label='val acc')
plt.legend(); plt.title("Training Accuracy"); plt.show()

# ---------------------------
# 7. Evaluation
# ---------------------------
y_pred_prob = model.predict(X_test).ravel()
y_pred = (y_pred_prob > 0.5).astype(int)

print("Test Accuracy:", accuracy_score(y_test, y_pred))
print("\nConfusion Matrix:\n", confusion_matrix(y_test, y_pred))
print("\nClassification Report:\n", classification_report(y_test, y_pred))

# ---------------------------
# 8. Predict Next-Day Trend
# ---------------------------
last_window = X_scaled[-WINDOW:]
last_window = last_window.reshape(1, WINDOW, X.shape[2])

next_prob = model.predict(last_window)[0,0]
prediction = "UP" if next_prob > 0.5 else "DOWN"

print("\n>>> Next-day predicted trend:", prediction,
      f"(Probability of UP = {next_prob:.2f})")

Q.2. Write a python program to implement simple Linear Regression for predicting house 
price. 

# Import necessary libraries
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
import matplotlib.pyplot as plt

# Step 1: Load the dataset
# (You can replace 'house_prices.csv' with your actual dataset file)
df = pd.read_csv("house_prices.csv")

print("‚úÖ Dataset loaded successfully!\n")
print("First 5 rows:\n", df.head(), "\n")

# Step 2: Define features (X) and target (y)
# Assuming dataset has columns like 'Area' (sq ft) and 'Price'
# Modify column names as per your dataset
X = df[['Area']]   # independent variable
y = df['Price']    # dependent variable

# Step 3: Split the dataset into training and testing sets (80%-20%)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Step 4: Create and train the Linear Regression model
model = LinearRegression()
model.fit(X_train, y_train)

# Step 5: Make predictions
y_pred = model.predict(X_test)

# Step 6: Evaluate the model
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print("üìä Model Evaluation:")
print("Mean Squared Error:", round(mse, 2))
print("R¬≤ Score:", round(r2, 4))
print("Intercept (b0):", round(model.intercept_, 2))
print("Slope (b1):", round(model.coef_[0], 2))

# Step 7: Visualize the results
plt.scatter(X_test, y_test, color='blue', label='Actual Prices')
plt.plot(X_test, y_pred, color='red', linewidth=2, label='Regression Line')
plt.title("Simple Linear Regression - House Price Prediction")
plt.xlabel("Area (sq ft)")
plt.ylabel("Price")
plt.legend()
plt.show()

# Step 8: Example prediction for new input
area_value = [[2500]]  # Example: 2500 sq ft
predicted_price = model.predict(area_value)
print(f"\nüè† Predicted price for {area_value[0][0]} sq ft = ${predicted_price[0]:.2f}")