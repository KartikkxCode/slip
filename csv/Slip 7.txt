Slip 7

Q.1 Fit the simple linear regression and polynomial linear regression models to Salary_positions.csv data. Find which one is more accurately fitting to the given data. Also predict the salaries of level 11 and level 12 employees

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import PolynomialFeatures
from sklearn.metrics import r2_score

# Step 1: Load the dataset
dataset = pd.read_csv('Salary_positions.csv')
X = dataset[['Level']]     # Feature: Position level (as DataFrame)
y = dataset['Salary']      # Target: Salary

# Step 2: Simple Linear Regression
lin_reg = LinearRegression()
lin_reg.fit(X, y)

# Step 3: Polynomial Regression (degree 2)
poly = PolynomialFeatures(degree=2)
X_poly = poly.fit_transform(X)

lin_reg_poly = LinearRegression()
lin_reg_poly.fit(X_poly, y)

#Step 4: Visualize Simple Linear Regression
plt.scatter(X, y, color='red')
plt.plot(X, lin_reg.predict(X), color='blue')
plt.title('Simple Linear Regression')
plt.xlabel('Position Level')
plt.ylabel('Salary')
plt.show()

#Step 5: Visualize Polynomial Regression
X_grid = np.arange(min(X['Level']), max(X['Level']) + 0.1, 0.1).reshape(-1, 1)
X_grid_df = pd.DataFrame(X_grid, columns=['Level'])

plt.scatter(X, y, color='red')
plt.plot(X_grid, lin_reg_poly.predict(poly.transform(X_grid_df)), color='green')
plt.title('Polynomial Regression (Degree 2)')
plt.xlabel('Position Level')
plt.ylabel('Salary')
plt.show()

#Step 6: Accuracy Comparison
y_pred_linear = lin_reg.predict(X)
y_pred_poly = lin_reg_poly.predict(X_poly)

r2_linear = r2_score(y, y_pred_linear)
r2_poly = r2_score(y, y_pred_poly)

print(f"R² Score (Linear Regression): {r2_linear:.4f}")
print(f"R² Score (Polynomial Regression): {r2_poly:.4f}")

#Step 7: Predictions for Level 11 and 12 
level_11 = pd.DataFrame([[11]], columns=['Level'])   
level_12 = pd.DataFrame([[12]], columns=['Level'])   

linear_pred_11 = lin_reg.predict(level_11)
linear_pred_12 = lin_reg.predict(level_12)

poly_pred_11 = lin_reg_poly.predict(poly.transform(level_11)) 
poly_pred_12 = lin_reg_poly.predict(poly.transform(level_12))  

print("\nPredicted Salaries:")
print(f"Linear - Level 11: ₹{linear_pred_11[0]:,.2f}")
print(f"Linear - Level 12: ₹{linear_pred_12[0]:,.2f}")
print(f"Polynomial - Level 11: ₹{poly_pred_11[0]:,.2f}")
print(f"Polynomial - Level 12: ₹{poly_pred_12[0]:,.2f}")


Q.2. Write a python program to implement Naive Bayes on weather forecast dataset. 

# Import necessary libraries
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import accuracy_score, classification_report

# Step 1: Create the Weather Forecast Dataset
data = {
    'Outlook': ['Sunny', 'Sunny', 'Overcast', 'Rain', 'Rain', 'Rain', 'Overcast',
                'Sunny', 'Sunny', 'Rain', 'Sunny', 'Overcast', 'Overcast', 'Rain'],
    'Temperature': ['Hot', 'Hot', 'Hot', 'Mild', 'Cool', 'Cool', 'Cool',
                    'Mild', 'Cool', 'Mild', 'Mild', 'Mild', 'Hot', 'Mild'],
    'Humidity': ['High', 'High', 'High', 'High', 'Normal', 'Normal', 'Normal',
                 'High', 'Normal', 'Normal', 'Normal', 'High', 'Normal', 'High'],
    'Windy': ['False', 'True', 'False', 'False', 'False', 'True', 'True',
              'False', 'False', 'False', 'True', 'True', 'False', 'True'],
    'Play': ['No', 'No', 'Yes', 'Yes', 'Yes', 'No', 'Yes',
             'No', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'No']
}

df = pd.DataFrame(data)
print("Dataset:\n", df, "\n")

# Step 2: Convert categorical data into numeric form using Label Encoding
le = LabelEncoder()
for column in df.columns:
    df[column] = le.fit_transform(df[column])

print("Encoded Dataset:\n", df, "\n")

# Step 3: Split features and target
X = df[['Outlook', 'Temperature', 'Humidity', 'Windy']]
y = df['Play']

# Step 4: Split dataset into train and test parts
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 5: Train Naive Bayes model
model = GaussianNB()
model.fit(X_train, y_train)

# Step 6: Predict on test data
y_pred = model.predict(X_test)

# Step 7: Evaluate the model
print("Predictions:", y_pred)
print("Accuracy:", accuracy_score(y_test, y_pred))
print("\nClassification Report:\n", classification_report(y_test, y_pred))

# Step 8: Example prediction
example = pd.DataFrame([[1, 2, 0, 1]], columns=['Outlook', 'Temperature', 'Humidity', 'Windy'])
predicted = model.predict(example)
print("\nExample Input: Overcast, Mild, High, True → Predicted Play:", le.inverse_transform(predicted))
